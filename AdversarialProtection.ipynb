{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Защита модели от Adversarial примеров\n",
    "\n",
    "Данная работа является продолжением предыдущей, в которой рассматривалось создание Adversarial примеров в задаче классификации изображений.\n",
    "\n",
    "Атака оказалась крайне удачной, и в ходе данной работы будут рассмотрены способы это исправить\n",
    "\n",
    "## Основные способы защиты, рассмотренные в работе:\n",
    "- [Ensemble adversarial training](https://arxiv.org/pdf/1705.07204) - модификация adversarial training, в которой adv. examples генерируются несколькими другими моделями\n",
    "- нормализация входных данных\n",
    "- использование небольшого dropout"
   ],
   "id": "4c963d313bb01bb3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Для начала зададим все необходимые параметры",
   "id": "6b604bdaca89bfd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T19:15:35.240617Z",
     "start_time": "2025-06-12T19:15:35.235691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "root   = Path(\"datasets/svhn_cls\")          # ваша готовая структура папок\n",
    "BATCH  = 128\n",
    "EPOCHS = 100\n",
    "EPS    = 2/255                              # сила FGSM (L∞)\n",
    "ADV_FRACTION = 0.5\n",
    "SEED = 17\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "device"
   ],
   "id": "53500154594501c8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Для нормализации нам нужно посчитать среднее и дисперсию нашего датасета. Заметим, что они считаются только по обучающей выборке, чтобы тестовая выборка никак не влияла на процесс обучения",
   "id": "6f931dc9dc190252"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-12T17:53:55.158344Z",
     "start_time": "2025-06-12T17:53:31.358653Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([0.4377, 0.4438, 0.4728])\n",
      "Std: tensor([0.1201, 0.1231, 0.1052])\n"
     ]
    }
   ],
   "execution_count": 2,
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path(\"datasets/svhn_cls/train\")\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=8)\n",
    "\n",
    "mean = 0.\n",
    "std = 0.\n",
    "nb_samples = 0.\n",
    "\n",
    "for data, _ in loader:\n",
    "    batch_samples = data.size(0)\n",
    "    data = data.view(batch_samples, data.size(1), -1)  # (B, C, H*W)\n",
    "    mean += data.mean(2).sum(0)\n",
    "    std += data.std(2).sum(0)\n",
    "    nb_samples += batch_samples\n",
    "\n",
    "mean /= nb_samples\n",
    "std /= nb_samples\n",
    "\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Std:\", std)"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Загрузим датасет, создадим трансформеры для него (с целью нормализации)",
   "id": "72e44148f3c3d665"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T17:56:16.615897Z",
     "start_time": "2025-06-12T17:56:16.422597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "root = Path(\"datasets/svhn_cls\")\n",
    "mean = (0.4377, 0.4438, 0.4728)\n",
    "std  = (0.1201, 0.1231, 0.1052)\n",
    "\n",
    "tf_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "tf_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "ds_train = datasets.ImageFolder(root / \"train\", transform=tf_train)\n",
    "ds_test  = datasets.ImageFolder(root / \"test\",  transform=tf_test)\n",
    "dl_train = DataLoader(ds_train, batch_size=128, shuffle=True,  num_workers=4, pin_memory=True)\n",
    "dl_test  = DataLoader(ds_test,  batch_size=256, shuffle=False, num_workers=4, pin_memory=True)"
   ],
   "id": "2283077fb3ba63f0",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Создадим наш ансамбль моделей, которые будут генерировать adv. examples\n",
    "\n",
    "Для этого возьмём готовый resnet и за finetune-им его на нашем датасете"
   ],
   "id": "f195cb920ae0a653"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T18:13:27.620516Z",
     "start_time": "2025-06-12T18:10:36.856789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "\n",
    "def finetune_resnet(seed=0):\n",
    "    torch.manual_seed(seed)\n",
    "    net = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "    net.fc = torch.nn.Linear(net.fc.in_features, 10)\n",
    "    net.to(device)\n",
    "    opt = torch.optim.Adam(net.parameters(), 1e-3)\n",
    "    net.train()\n",
    "    for _ in range(3):                      # быстрый 3-эпоховый fine-tune\n",
    "        for x, y in DataLoader(ds_train, BATCH*2, shuffle=True):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            opt.zero_grad()\n",
    "            F.cross_entropy(net(x), y).backward()\n",
    "            opt.step()\n",
    "    net.eval()\n",
    "    for p in net.parameters():              # freeze\n",
    "        p.requires_grad_(False)\n",
    "    return net\n",
    "\n",
    "src_nets = [finetune_resnet(seed) for seed in (42, 99)]"
   ],
   "id": "9463e65f8d37ade2",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Создадим нашу основную модель, которую мы будем обучать\n",
    "\n",
    "Последний (линейный) слой классификатора заменим, чтобы он предсказывал один из 10 классов (в предыдущей работе за нас это делал ultralytics, здесь же это приходится делать вручную)\n",
    "\n",
    "Оптимизатор и планировщик так же раньше за нас добавляла библиотека, сейчас просто используем наиболее подходящие"
   ],
   "id": "b732f00007f32504"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T18:24:01.212795Z",
     "start_time": "2025-06-12T18:24:01.072003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "from ultralytics import YOLO\n",
    "\n",
    "yolo = YOLO(\"yolov8s-cls.pt\")\n",
    "net  = yolo.model\n",
    "\n",
    "head = net.model[-1]\n",
    "in_f = head.linear.in_features\n",
    "head.linear = nn.Linear(in_f, 10, bias=True)\n",
    "net.to(device)\n",
    "\n",
    "opt  = torch.optim.AdamW(net.parameters(), 1e-3)\n",
    "sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, EPOCHS*len(dl_train))"
   ],
   "id": "3e809905e5646e97",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Напишем свой вариант FGSM-атаки. Очень хотелось бы использовать реализацию из ART, однако она может работать только на процессоре, и постоянные переводы с GPU на CPU существенно замедлят обучение",
   "id": "f3ba6e557aa07249"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T18:52:57.693799Z",
     "start_time": "2025-06-12T18:52:57.690292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_logits(model, x):\n",
    "    out = model(x)\n",
    "    return out[0] if isinstance(out, (tuple, list)) else out\n",
    "\n",
    "def fgsm(images, labels, src_model):\n",
    "    images = images.clone().detach().requires_grad_(True)\n",
    "    logits = get_logits(src_model, images)\n",
    "    loss    = F.cross_entropy(logits, labels)\n",
    "    loss.backward()\n",
    "    adv = (images + EPS * images.grad.sign()).clamp(0, 1).detach()\n",
    "    return adv"
   ],
   "id": "1a478a6b5777cc6a",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Объявим ещё полезную функцию, которую будем вызывать каждые 10 эпох",
   "id": "c917b954136132df"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T19:00:25.158378Z",
     "start_time": "2025-06-12T19:00:25.152380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def validate_and_checkpoint(\n",
    "        epoch: int,\n",
    "        net: torch.nn.Module,\n",
    "        dl_test: torch.utils.data.DataLoader,\n",
    "        ds_test_len: int,\n",
    "        fgsm_fn,\n",
    "        ckpt_dir: Path,\n",
    "        opt: torch.optim.Optimizer,\n",
    "        sched,\n",
    "        best_robust: float,\n",
    "        get_logits_fn,\n",
    "        eps: float = 2 / 255\n",
    "    ) -> float:\n",
    "    net.eval()\n",
    "    clean_hits = robust_hits = 0\n",
    "\n",
    "    for x, y in dl_test:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            clean_logits = get_logits_fn(net, x)\n",
    "\n",
    "        adv_x = fgsm_fn(x, y, net)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            adv_logits = get_logits_fn(net, adv_x)\n",
    "\n",
    "        clean_hits  += (clean_logits.argmax(1) == y).sum().item()\n",
    "        robust_hits += (adv_logits.argmax(1)  == y).sum().item()\n",
    "\n",
    "    clean_acc  = clean_hits  / ds_test_len\n",
    "    robust_acc = robust_hits / ds_test_len\n",
    "\n",
    "    print(f\"\\nEpoch {epoch:02d}: \"\n",
    "          f\"clean {clean_acc:.3f} | FGSM ε={eps} {robust_acc:.3f}\")\n",
    "\n",
    "    # ----------- сохранить обычный чекпоинт -----------\n",
    "    ckpt_path = ckpt_dir / f\"epoch_{epoch:02d}.pth\"\n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state\": net.state_dict(),\n",
    "        \"optimizer_state\": opt.state_dict(),\n",
    "        \"scheduler_state\": sched.state_dict(),\n",
    "        \"clean_acc\": clean_acc,\n",
    "        \"robust_acc\": robust_acc,\n",
    "    }, ckpt_path)\n",
    "    print(f\"Saved checkpoint ➜ {ckpt_path.name}\")\n",
    "\n",
    "    # ----------- сохранить лучший ---------------------\n",
    "    if robust_acc > best_robust:\n",
    "        best_robust = robust_acc\n",
    "        best_path   = ckpt_dir / \"best.pth\"\n",
    "        torch.save(net.state_dict(), best_path)\n",
    "        print(f\"New best robust_acc = {best_robust:.3f} ➜ {best_path.name}\")\n",
    "\n",
    "    net.train()            # вернуться к обучению\n",
    "    return best_robust"
   ],
   "id": "da56d5acfaec5dc0",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Наконец, можем переходить к обучению",
   "id": "32bbe91859a6e174"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T19:41:33.556340Z",
     "start_time": "2025-06-12T19:15:38.819597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "ckpt_dir = Path(\"checkpoints_eat\")\n",
    "ckpt_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "best_robust = 0.0\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    net.train()\n",
    "    running_acc = 0\n",
    "    pbar = tqdm(dl_train, desc=f\"Epoch {epoch:02d}/{EPOCHS}\", leave=False)\n",
    "\n",
    "    for step, (imgs, lbls) in enumerate(pbar, 1):\n",
    "        imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "\n",
    "        # добавляем adv. examples\n",
    "        src = random.choice(src_nets + [net])\n",
    "        adv = fgsm(imgs, lbls, src)\n",
    "        k   = int(imgs.size(0) * ADV_FRACTION)\n",
    "\n",
    "        mix_imgs   = torch.cat([imgs[:k], adv[:k]])\n",
    "        mix_labels = torch.cat([lbls[:k], lbls[:k]])\n",
    "\n",
    "        #  шаг оптимизации\n",
    "        opt.zero_grad()\n",
    "        logits = get_logits(net, mix_imgs)\n",
    "        loss   = F.cross_entropy(logits, mix_labels, label_smoothing=0.1)\n",
    "        loss.backward(); opt.step(); sched.step()\n",
    "\n",
    "        # обновляем прогресс бар\n",
    "        pred = logits.argmax(1)\n",
    "        running_acc += (pred == mix_labels).sum().item()\n",
    "        avg_acc = running_acc / (step * mix_labels.size(0))\n",
    "        pbar.set_postfix(loss=f\"{loss.item():.3f}\",\n",
    "                 clean_acc=f\"{(pred[:k]==lbls[:k]).float().mean():.3f}\",\n",
    "                 mix_acc=f\"{avg_acc:.3f}\")\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == EPOCHS:\n",
    "        best_robust = validate_and_checkpoint(\n",
    "            epoch         = epoch,\n",
    "            net           = net,\n",
    "            dl_test       = dl_test,\n",
    "            ds_test_len   = len(ds_test),\n",
    "            fgsm_fn       = fgsm,\n",
    "            ckpt_dir      = ckpt_dir,\n",
    "            opt           = opt,\n",
    "            sched         = sched,\n",
    "            best_robust   = best_robust,\n",
    "            get_logits_fn = get_logits,\n",
    "            eps           = EPS\n",
    "        )"
   ],
   "id": "bd15b28ac8916e3e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: clean 0.330 | FGSM ε=0.00784313725490196 0.334\n",
      "Saved checkpoint ➜ epoch_10.pth\n",
      "New best robust_acc = 0.334 ➜ best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20: clean 0.317 | FGSM ε=0.00784313725490196 0.323\n",
      "Saved checkpoint ➜ epoch_20.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30: clean 0.306 | FGSM ε=0.00784313725490196 0.307\n",
      "Saved checkpoint ➜ epoch_30.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40: clean 0.290 | FGSM ε=0.00784313725490196 0.299\n",
      "Saved checkpoint ➜ epoch_40.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 50: clean 0.286 | FGSM ε=0.00784313725490196 0.298\n",
      "Saved checkpoint ➜ epoch_50.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 60: clean 0.282 | FGSM ε=0.00784313725490196 0.295\n",
      "Saved checkpoint ➜ epoch_60.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                           \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[38]\u001B[39m\u001B[32m, line 13\u001B[39m\n\u001B[32m     10\u001B[39m running_acc = \u001B[32m0\u001B[39m\n\u001B[32m     11\u001B[39m pbar = tqdm(dl_train, desc=\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m02d\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mEPOCHS\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m, leave=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m---> \u001B[39m\u001B[32m13\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mimgs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlbls\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mpbar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m     14\u001B[39m \u001B[43m    \u001B[49m\u001B[43mimgs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlbls\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mimgs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlbls\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     16\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# добавляем adv. examples\u001B[39;49;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\std.py:1181\u001B[39m, in \u001B[36mtqdm.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1178\u001B[39m time = \u001B[38;5;28mself\u001B[39m._time\n\u001B[32m   1180\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1181\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m   1182\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\n\u001B[32m   1183\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Update and possibly print the progressbar.\u001B[39;49;00m\n\u001B[32m   1184\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;49;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:438\u001B[39m, in \u001B[36mDataLoader.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    436\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._iterator\n\u001B[32m    437\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m438\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_get_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:386\u001B[39m, in \u001B[36mDataLoader._get_iterator\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    384\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    385\u001B[39m     \u001B[38;5;28mself\u001B[39m.check_worker_number_rationality()\n\u001B[32m--> \u001B[39m\u001B[32m386\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_MultiProcessingDataLoaderIter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1039\u001B[39m, in \u001B[36m_MultiProcessingDataLoaderIter.__init__\u001B[39m\u001B[34m(self, loader)\u001B[39m\n\u001B[32m   1032\u001B[39m w.daemon = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m   1033\u001B[39m \u001B[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001B[39;00m\n\u001B[32m   1034\u001B[39m \u001B[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001B[39;00m\n\u001B[32m   1035\u001B[39m \u001B[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001B[39;00m\n\u001B[32m   1036\u001B[39m \u001B[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001B[39;00m\n\u001B[32m   1037\u001B[39m \u001B[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001B[39;00m\n\u001B[32m   1038\u001B[39m \u001B[38;5;66;03m#     AssertionError: can only join a started process.\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1039\u001B[39m \u001B[43mw\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1040\u001B[39m \u001B[38;5;28mself\u001B[39m._index_queues.append(index_queue)\n\u001B[32m   1041\u001B[39m \u001B[38;5;28mself\u001B[39m._workers.append(w)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\process.py:121\u001B[39m, in \u001B[36mBaseProcess.start\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    118\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _current_process._config.get(\u001B[33m'\u001B[39m\u001B[33mdaemon\u001B[39m\u001B[33m'\u001B[39m), \\\n\u001B[32m    119\u001B[39m        \u001B[33m'\u001B[39m\u001B[33mdaemonic processes are not allowed to have children\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m    120\u001B[39m _cleanup()\n\u001B[32m--> \u001B[39m\u001B[32m121\u001B[39m \u001B[38;5;28mself\u001B[39m._popen = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    122\u001B[39m \u001B[38;5;28mself\u001B[39m._sentinel = \u001B[38;5;28mself\u001B[39m._popen.sentinel\n\u001B[32m    123\u001B[39m \u001B[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001B[39;00m\n\u001B[32m    124\u001B[39m \u001B[38;5;66;03m# reference to the process object (see bpo-30775)\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\context.py:224\u001B[39m, in \u001B[36mProcess._Popen\u001B[39m\u001B[34m(process_obj)\u001B[39m\n\u001B[32m    222\u001B[39m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[32m    223\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_Popen\u001B[39m(process_obj):\n\u001B[32m--> \u001B[39m\u001B[32m224\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_context\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mProcess\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\context.py:336\u001B[39m, in \u001B[36mSpawnProcess._Popen\u001B[39m\u001B[34m(process_obj)\u001B[39m\n\u001B[32m    333\u001B[39m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[32m    334\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_Popen\u001B[39m(process_obj):\n\u001B[32m    335\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpopen_spawn_win32\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Popen\n\u001B[32m--> \u001B[39m\u001B[32m336\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\popen_spawn_win32.py:95\u001B[39m, in \u001B[36mPopen.__init__\u001B[39m\u001B[34m(self, process_obj)\u001B[39m\n\u001B[32m     93\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     94\u001B[39m     reduction.dump(prep_data, to_child)\n\u001B[32m---> \u001B[39m\u001B[32m95\u001B[39m     \u001B[43mreduction\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mto_child\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     96\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m     97\u001B[39m     set_spawning_popen(\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\reduction.py:60\u001B[39m, in \u001B[36mdump\u001B[39m\u001B[34m(obj, file, protocol)\u001B[39m\n\u001B[32m     58\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdump\u001B[39m(obj, file, protocol=\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m     59\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m60\u001B[39m     \u001B[43mForkingPickler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 38
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
