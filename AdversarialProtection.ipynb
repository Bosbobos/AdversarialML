{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cddf8587116c0f",
   "metadata": {},
   "source": [
    "# Защита модели от Adversarial примеров\n",
    "\n",
    "Работа выполнена студентом БИБ233 МИЭМ НИУ ВШЭ Коноваловым Матвеем.\n",
    "\n",
    "Данная работа является продолжением предыдущей, в которой рассматривалось создание Adversarial примеров в задаче классификации изображений.\n",
    "\n",
    "Атака оказалась крайне удачной, и в ходе данной работы будут рассмотрены способы это исправить.\n",
    "\n",
    "## Основные способы защиты, рассмотренные в работе:\n",
    "- Adversarial training\n",
    "- нормализация входных данных\n",
    "- использование небольшого dropout\n",
    "\n",
    "Все эти изменения будут вноситься при помощи библиотеки Adversarial Robustness Toolbox."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b925fd6341e2c4e",
   "metadata": {},
   "source": [
    "Зададим все необходимые параметры. В MODEL_PATH укажите, куда вы положили [обученную модель из предыдущего пункта](https://disk.360.yandex.ru/d/r-5SqYBdwTfuuQ)"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2025-06-14T13:57:13.079732Z",
     "start_time": "2025-06-14T13:57:13.072207Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "IMG_SIZE = 224\n",
    "MODEL_PATH = Path('models/best.pt')\n",
    "DATA_DIR = Path(\"datasets/svhn_cls\")\n",
    "mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "std = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "LR = 1e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "EPS = 8/255\n",
    "EPS_STEP = 0.007\n",
    "BETA = 6\n",
    "MAX_PGD_ITERS = 3\n",
    "SEED = 17\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 96
  },
  {
   "cell_type": "markdown",
   "id": "e7a8e8c7cde0665f",
   "metadata": {},
   "source": [
    "Считаем наш датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c41b35aa14d3d36",
   "metadata": {},
   "source": [
    "В качестве первого метода защиты добавим нормализацию входов в модель. Это уже должно будет снизить эффективность Adv. примеров, поскольку они существенно отличаются от нормальных примеров."
   ]
  },
  {
   "cell_type": "code",
   "id": "e265f7fbe01e8266",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T10:50:48.517714Z",
     "start_time": "2025-06-14T10:50:48.513851Z"
    }
   },
   "source": [
    "from art.preprocessing.standardisation_mean_std import StandardisationMeanStd\n",
    "\n",
    "norm_proc = StandardisationMeanStd(\n",
    "    mean=mean,\n",
    "    std =std\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 65
  },
  {
   "cell_type": "markdown",
   "id": "81ce71c0646429fe",
   "metadata": {},
   "source": [
    "Загрузим нашу уязвимую модель. Мы не будем обучать новую модель с нуля, вместо этого мы её дообучим"
   ]
  },
  {
   "cell_type": "code",
   "id": "132d6326fc63d55d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T12:44:09.159779Z",
     "start_time": "2025-06-14T12:44:09.155778Z"
    }
   },
   "source": [
    "class YoloClsAdapter(torch.nn.Module):\n",
    "    def __init__(self, core_model):\n",
    "        super().__init__()\n",
    "        self.core = core_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.core(x)\n",
    "        if isinstance(y, (tuple, list)):\n",
    "            y = y[-1]\n",
    "        return y"
   ],
   "outputs": [],
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "id": "666328e7bef43300",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T20:37:15.245684Z",
     "start_time": "2025-06-14T20:37:15.209041Z"
    }
   },
   "source": [
    "from ultralytics import YOLO\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "\n",
    "yolo  = YOLO(MODEL_PATH)\n",
    "for p in yolo.model.parameters():\n",
    "    p.requires_grad_(True)\n",
    "adapter = YoloClsAdapter(yolo.model).to(device)\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    adapter.parameters(),\n",
    "    lr=LR,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "classifier = PyTorchClassifier(\n",
    "    model=adapter,\n",
    "    loss=loss,\n",
    "    optimizer=optimizer,\n",
    "    nb_classes=10,\n",
    "    input_shape=(3, IMG_SIZE, IMG_SIZE),\n",
    "    clip_values=(0.0, 1.0),\n",
    "    device_type=device\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 124
  },
  {
   "cell_type": "markdown",
   "id": "4f40174e83a4104c",
   "metadata": {},
   "source": [
    "В качестве генератора Adversarial examples выберем даже более сильный метод, чем FGSM из предыдущей работы - ProjectedGradientDescent. Это обеспечит защиту как от более слабого метода, так и от некоторых более сильных"
   ]
  },
  {
   "cell_type": "code",
   "id": "328db6c63686c60e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T10:52:02.103776Z",
     "start_time": "2025-06-14T10:52:02.099770Z"
    }
   },
   "source": [
    "from art.attacks.evasion import ProjectedGradientDescent\n",
    "\n",
    "pgd_attack = ProjectedGradientDescent(\n",
    "    estimator=classifier,\n",
    "    norm=np.inf,\n",
    "    eps=EPS,\n",
    "    eps_step=EPS_STEP,\n",
    "    max_iter=MAX_PGD_ITERS,\n",
    "    targeted=False,\n",
    "    verbose=False\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 68
  },
  {
   "cell_type": "markdown",
   "id": "1369c19fb6208e01",
   "metadata": {},
   "source": [
    "Наконец, создадим наш класс для адверсариального обучения и дообучим нашу модель на 10 эпохах"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T17:02:32.398970Z",
     "start_time": "2025-06-14T17:02:20.685320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from art.data_generators import PyTorchDataGenerator\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "CHUNK = 5_000\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS     = 5\n",
    "SHUFFLE_DS = False\n",
    "\n",
    "torch_transforms = yolo.model.transforms\n",
    "train_ds = ImageFolder(root=DATA_DIR / \"train\",\n",
    "                       transform=torch_transforms)\n",
    "train_loader = DataLoader(train_ds,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=SHUFFLE_DS,\n",
    "                          num_workers=4,\n",
    "                          pin_memory=True)\n",
    "train_gen = PyTorchDataGenerator(iterator=train_loader,\n",
    "                                 size=len(train_ds),\n",
    "                                 batch_size=BATCH_SIZE)"
   ],
   "id": "ac22eff68065943",
   "outputs": [],
   "execution_count": 110
  },
  {
   "cell_type": "code",
   "id": "afc822c6bb08b16f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T21:10:17.820219Z",
     "start_time": "2025-06-14T20:37:20.943460Z"
    }
   },
   "source": [
    "from art.defences.trainer import AdversarialTrainerFBFPyTorch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "classifier._int_labels = True\n",
    "classifier._reduce_labels = False\n",
    "\n",
    "adv_trainer = AdversarialTrainerFBFPyTorch(\n",
    "    classifier,\n",
    "    eps = 4\n",
    ")\n",
    "\n",
    "adv_trainer.fit_generator(        # !!\n",
    "    generator=train_gen,          # функция, порождающая генератор на каждый epoch\n",
    "    nb_epochs=1\n",
    ")\n",
    "\n",
    "robust_classifier = adv_trainer.get_classifier()\n",
    "robust_classifier.save('robust_classifier7.pt', 'models')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adversarial Training FBF - Epochs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "72b12341c4bd4afe8d6d7e45f5a6953c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 125
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Сохраним обученную модель",
   "id": "bbb4b619730c14d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T23:10:36.131300Z",
     "start_time": "2025-06-13T23:10:35.964654Z"
    }
   },
   "cell_type": "code",
   "source": "robust_classifier.save('robust_classifier2.pt', 'models')",
   "id": "f9ddd626021f542a",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T09:31:10.978759Z",
     "start_time": "2025-06-14T09:31:10.881819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = torch.load('models/robust_classifier2.pt.model')\n",
    "data.keys"
   ],
   "id": "fb0439ff90faa2e7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function OrderedDict.keys>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T09:39:22.084207Z",
     "start_time": "2025-06-14T09:39:21.939910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "yolo = YOLO(MODEL_PATH)\n",
    "adapter = YoloClsAdapter(yolo.model).to(device)\n",
    "adapter.load_state_dict(torch.load('models/robust_classifier2.pt.model'))\n",
    "robust_classifier = PyTorchClassifier(\n",
    "    model=adapter,\n",
    "    loss=torch.nn.CrossEntropyLoss(),\n",
    "    nb_classes=10,\n",
    "    input_shape=(3, IMG_SIZE, IMG_SIZE),\n",
    "    clip_values=(0.0, 1.0),\n",
    "    device_type=device\n",
    ")"
   ],
   "id": "4e728f1ca508233a",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Теперь сравним качество изначальной и дообученной моделей как на чистой, так и на adv. выборках",
   "id": "eb89aca0c8aa1571"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T08:50:13.832865Z",
     "start_time": "2025-06-14T08:50:13.780994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from art.estimators.classification import PyTorchClassifier\n",
    "\n",
    "basic_yolo  = YOLO(MODEL_PATH)\n",
    "adapter = YoloClsAdapter(basic_yolo.model).to(device).eval()\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "basic_cls = PyTorchClassifier(\n",
    "    model=adapter,\n",
    "    loss=loss,\n",
    "    nb_classes=10,\n",
    "    input_shape=(3, IMG_SIZE, IMG_SIZE),\n",
    "    clip_values=(0.0, 1.0),\n",
    "    device_type=device\n",
    ")"
   ],
   "id": "6ed993476e1969b4",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T16:49:21.118133Z",
     "start_time": "2025-06-14T16:49:19.408672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "\n",
    "N_SAMPLES = 1000\n",
    "\n",
    "all_files = list((DATA_DIR / 'test').glob(\"*/*.png\"))\n",
    "assert all_files, f\"Ничего не найдено в {DATA_DIR}\"\n",
    "\n",
    "idx_files = random.sample(all_files, N_SAMPLES) # Выбираем N_SAMPLES картинок\n",
    "\n",
    "x, y = [], []\n",
    "for fp in idx_files:\n",
    "    img = Image.open(fp).convert(\"RGB\")\n",
    "    arr = basic_yolo.model.transforms(img)\n",
    "    x.append(arr)\n",
    "    y.append(int(fp.parent.name))\n",
    "\n",
    "clean_x = np.stack(x, axis=0)\n",
    "clean_y = np.asarray(y)\n",
    "clean_y"
   ],
   "id": "22029ee8158fea04",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 3, 2, 3, 2, 1, 9, 8, 8, 5, 7, 2, 1, 0, 2, 3, 9, 3, 2, 5, 2, 7, 7, 8, 3, 1, 5, 1, 1, 9, 1, 1, 8, 5, 5, 7, 2, 2, 5, 1, 8, 7, 1, 2, 3, 1, 5, 4, 7, 6, 1, 7, 3, 5, 3, 0, 4, 3, 5, 0, 9, 8, 3, 0, 4, 3, 6, 9, 0, 3, 2, 1, 5, 2, 2, 5, 3, 1, 2, 1, 9, 2, 1, 9, 6, 5, 5, 5, 1, 2, 7, 2, 3, 2, 1, 2, 1, 6, 6, 9, 2, 2, 0, 0,\n",
       "       9, 3, 0, 4, 8, 2, 4, 6, 1, 8, 1, 2, 2, 1, 9, 8, 4, 0, 6, 5, 5, 7, 1, 3, 4, 8, 6, 3, 1, 1, 2, 1, 7, 1, 2, 0, 5, 2, 2, 2, 0, 1, 3, 1, 7, 9, 2, 2, 7, 3, 4, 5, 1, 5, 7, 2, 2, 5, 2, 6, 1, 2, 0, 8, 4, 6, 3, 4, 2, 5, 3, 5, 6, 4, 1, 4, 9, 2, 2, 4, 2, 1, 3, 6, 0, 8, 6, 5, 5, 3, 1, 2, 6, 1, 5, 2, 6, 2, 3, 1, 9, 2, 2, 4,\n",
       "       3, 4, 6, 1, 5, 1, 5, 0, 1, 6, 8, 9, 1, 4, 4, 4, 5, 1, 5, 5, 4, 4, 0, 2, 2, 1, 0, 4, 3, 9, 2, 0, 2, 1, 5, 7, 8, 0, 0, 1, 4, 8, 2, 6, 1, 9, 1, 9, 0, 4, 5, 9, 2, 7, 0, 3, 9, 1, 4, 1, 8, 5, 1, 1, 5, 2, 2, 3, 3, 5, 6, 3, 3, 0, 5, 9, 3, 1, 9, 9, 9, 0, 6, 8, 2, 2, 2, 1, 2, 1, 5, 2, 4, 2, 4, 1, 2, 2, 1, 7, 3, 2, 7, 1,\n",
       "       4, 3, 1, 2, 5, 9, 5, 1, 9, 2, 1, 4, 4, 5, 3, 9, 5, 6, 9, 1, 7, 5, 1, 1, 6, 5, 2, 4, 2, 3, 1, 6, 2, 1, 8, 2, 4, 5, 2, 5, 9, 4, 9, 5, 1, 2, 2, 4, 2, 5, 1, 3, 0, 7, 1, 2, 4, 1, 4, 1, 5, 3, 2, 1, 1, 2, 1, 2, 3, 9, 4, 2, 1, 1, 8, 2, 2, 3, 2, 6, 5, 6, 1, 4, 1, 9, 7, 6, 9, 9, 2, 2, 2, 2, 5, 3, 8, 4, 3, 2, 1, 2, 3, 7,\n",
       "       1, 2, 0, 0, 5, 6, 1, 3, 7, 7, 4, 3, 3, 6, 2, 7, 2, 4, 9, 1, 3, 2, 1, 1, 3, 8, 8, 1, 2, 9, 6, 3, 1, 4, 7, 1, 3, 8, 5, 9, 1, 6, 4, 8, 4, 7, 1, 1, 2, 4, 9, 3, 2, 7, 3, 3, 4, 2, 7, 2, 2, 3, 2, 1, 4, 0, 4, 1, 3, 7, 4, 1, 1, 4, 0, 2, 4, 1, 1, 1, 2, 1, 0, 1, 2, 4, 1, 1, 2, 6, 7, 2, 5, 2, 7, 5, 2, 5, 0, 9, 7, 0, 8, 5,\n",
       "       2, 5, 6, 1, 8, 1, 2, 2, 6, 3, 4, 2, 9, 5, 1, 0, 3, 3, 4, 4, 2, 9, 4, 3, 2, 0, 6, 1, 3, 5, 9, 1, 3, 1, 6, 5, 1, 0, 8, 3, 1, 7, 8, 4, 1, 7, 1, 5, 4, 0, 7, 2, 0, 6, 1, 9, 1, 1, 4, 2, 2, 9, 7, 2, 2, 6, 2, 5, 0, 4, 1, 3, 0, 7, 4, 1, 2, 5, 9, 2, 8, 4, 9, 1, 4, 1, 5, 7, 4, 2, 6, 1, 8, 6, 7, 1, 9, 1, 7, 2, 7, 0, 1, 5,\n",
       "       7, 1, 2, 9, 3, 9, 1, 1, 9, 3, 1, 4, 5, 3, 3, 9, 7, 6, 2, 5, 8, 3, 6, 1, 9, 8, 2, 2, 2, 7, 2, 4, 2, 9, 2, 6, 1, 1, 9, 5, 4, 1, 4, 4, 3, 4, 6, 0, 1, 1, 2, 0, 2, 0, 2, 8, 3, 4, 3, 8, 0, 5, 5, 5, 9, 0, 0, 6, 5, 9, 2, 8, 6, 9, 1, 9, 3, 6, 6, 7, 2, 6, 2, 2, 5, 4, 1, 1, 0, 1, 4, 5, 1, 8, 4, 6, 0, 0, 1, 3, 3, 7, 8, 3,\n",
       "       1, 2, 1, 1, 1, 8, 0, 6, 2, 1, 2, 3, 8, 3, 2, 8, 8, 4, 4, 1, 1, 1, 2, 4, 1, 2, 5, 8, 6, 2, 2, 4, 2, 5, 3, 0, 4, 2, 9, 1, 5, 2, 2, 1, 0, 3, 1, 8, 0, 3, 9, 2, 2, 2, 5, 1, 1, 6, 6, 0, 4, 0, 8, 9, 7, 4, 3, 3, 2, 5, 5, 4, 1, 0, 1, 1, 6, 1, 2, 9, 6, 3, 7, 0, 1, 2, 1, 2, 8, 1, 8, 3, 2, 4, 2, 5, 4, 2, 7, 8, 6, 8, 3, 2,\n",
       "       1, 5, 6, 4, 2, 4, 5, 2, 6, 1, 8, 9, 9, 5, 9, 2, 1, 2, 0, 0, 8, 2, 9, 1, 1, 3, 1, 4, 2, 1, 9, 3, 1, 4, 6, 4, 2, 1, 4, 4, 2, 6, 2, 3, 0, 9, 2, 5, 1, 9, 5, 7, 1, 3, 6, 2, 4, 2, 6, 2, 5, 1, 3, 4, 7, 2, 9, 2, 2, 1, 8, 4, 2, 4, 3, 7, 0, 5, 9, 1, 3, 7, 3, 0, 2, 8, 4, 2, 1, 6, 7, 7, 2, 5, 3, 8, 2, 7, 2, 0, 2, 0, 4, 1,\n",
       "       9, 4, 0, 3, 7, 8, 3, 6, 2, 9, 6, 7, 2, 2, 5, 2, 5, 5, 1, 0, 2, 6, 3, 8, 6, 8, 2, 5, 1, 7, 4, 0, 1, 6, 9, 6, 3, 0, 1, 2, 5, 2, 5, 8, 2, 5, 0, 3, 3, 1, 2, 9, 8, 7, 8, 6, 2, 7, 5, 5, 3, 6, 2, 6])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T09:33:34.936736Z",
     "start_time": "2025-06-14T09:33:24.523640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from art.attacks.evasion import FastGradientMethod\n",
    "\n",
    "EPS = 8/255\n",
    "\n",
    "# Генерируем FGSM по изначальной модели\n",
    "basic_fgsm = FastGradientMethod(estimator=basic_cls, eps=EPS)\n",
    "basic_x_fgsm  = basic_fgsm.generate(x=clean_x)\n",
    "\n",
    "# FGSM по защищённой модели\n",
    "robust_fgsm = FastGradientMethod(estimator=robust_classifier, eps=EPS)\n",
    "robust_x_fgsm  = basic_fgsm.generate(x=clean_x)"
   ],
   "id": "c5542e50479de86d",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T16:46:54.132289Z",
     "start_time": "2025-06-14T16:46:52.235825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_gen = ChunkedGenerator(\n",
    "    DATA_DIR / \"test\",\n",
    "    chunk=1000,\n",
    "    batch_size=1000,\n",
    "    shuffle=False,\n",
    ")\n",
    "x, y = train_gen.get_batch()"
   ],
   "id": "98d9e655df75266a",
   "outputs": [],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T21:10:31.822199Z",
     "start_time": "2025-06-14T21:10:30.076594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(clean_y, robust_classifier.predict(clean_x).argmax(1))"
   ],
   "id": "9ae348290692a986",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.068"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T20:32:28.136104Z",
     "start_time": "2025-06-14T20:32:21.842384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ❶ Cводим всё в словари --------------------------------------------------------\n",
    "tests   = dict(  # порядок сохранится как объявлен\n",
    "    clean_train   = clean_x,\n",
    "    basic_x_fgsm  = basic_x_fgsm,\n",
    "    robust_x_fgsm = robust_x_fgsm\n",
    ")\n",
    "models  = dict(basic = basic_cls, robust = robust_classifier)\n",
    "\n",
    "# ❷ Предсказания всех (model × test) за один проход ----------------------------\n",
    "preds = {\n",
    "    (m, t): mdl.predict(x).argmax(1)          # argmax → метки классов\n",
    "    for m, mdl in models.items()\n",
    "    for t, x   in tests.items()\n",
    "}\n",
    "\n",
    "cols = [\"basic_accuracy\", \"basic_ASR\", \"robust_accuracy\", \"robust_ASR\"]\n",
    "df = pd.DataFrame(index=tests, columns=cols, dtype=\"float32\")\n",
    "\n",
    "for m in models:\n",
    "    clean_pred = preds[(m, \"clean_train\")]\n",
    "    acc_col = f\"{m}_accuracy\"\n",
    "    asr_col = f\"{m}_ASR\"\n",
    "\n",
    "    for t in tests:\n",
    "        adv_pred = preds[(m, t)]\n",
    "        accuracy = np.mean(adv_pred == clean_y)\n",
    "        if t == \"clean_train\":\n",
    "            asr = 0\n",
    "        else:\n",
    "            asr = np.mean((clean_pred == clean_y) & (adv_pred != clean_y))\n",
    "\n",
    "        df.at[t, acc_col] = accuracy\n",
    "        df.at[t, asr_col] = asr\n",
    "\n",
    "df"
   ],
   "id": "2e7dee92aa45c1e7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ok__\\AppData\\Local\\Temp\\ipykernel_19856\\1630435535.py:34: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.973' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  df.at[t, acc_col] = accuracy\n",
      "C:\\Users\\ok__\\AppData\\Local\\Temp\\ipykernel_19856\\1630435535.py:35: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.804' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  df.at[t, asr_col] = asr\n",
      "C:\\Users\\ok__\\AppData\\Local\\Temp\\ipykernel_19856\\1630435535.py:34: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.191' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  df.at[t, acc_col] = accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "               basic_accuracy  basic_ASR  robust_accuracy  robust_ASR\n",
       "clean_train             0.973      0.000            0.191         0.0\n",
       "basic_x_fgsm            0.172      0.804            0.191         0.0\n",
       "robust_x_fgsm           0.172      0.804            0.191         0.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>basic_accuracy</th>\n",
       "      <th>basic_ASR</th>\n",
       "      <th>robust_accuracy</th>\n",
       "      <th>robust_ASR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clean_train</th>\n",
       "      <td>0.973</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basic_x_fgsm</th>\n",
       "      <td>0.172</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robust_x_fgsm</th>\n",
       "      <td>0.172</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 121
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
