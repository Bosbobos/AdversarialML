{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cddf8587116c0f",
   "metadata": {},
   "source": [
    "# Защита модели от Adversarial примеров\n",
    "\n",
    "Работа выполнена студентом БИБ233 МИЭМ НИУ ВШЭ Коноваловым Матвеем.\n",
    "\n",
    "Данная работа является продолжением предыдущей, в которой рассматривалось создание Adversarial примеров в задаче классификации изображений.\n",
    "\n",
    "Атака оказалась крайне удачной, и в ходе данной работы будут рассмотрены способы это исправить.\n",
    "\n",
    "## Основные способы защиты, рассмотренные в работе:\n",
    "- Adversarial training\n",
    "- нормализация входных данных\n",
    "- использование небольшого dropout\n",
    "\n",
    "Все эти изменения будут вноситься при помощи библиотеки Adversarial Robustness Toolbox."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b925fd6341e2c4e",
   "metadata": {},
   "source": [
    "Зададим все необходимые параметры. В MODEL_PATH укажите, куда вы положили [обученную модель из предыдущего пункта](https://disk.360.yandex.ru/d/r-5SqYBdwTfuuQ)"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2025-06-14T13:57:13.079732Z",
     "start_time": "2025-06-14T13:57:13.072207Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "IMG_SIZE = 224\n",
    "MODEL_PATH = Path('models/best.pt')\n",
    "DATA_DIR = Path(\"datasets/svhn_cls\")\n",
    "mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "std = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "LR = 1e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "EPS = 8/255\n",
    "EPS_STEP = 0.007\n",
    "BETA = 6\n",
    "MAX_PGD_ITERS = 3\n",
    "SEED = 17\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 96
  },
  {
   "cell_type": "markdown",
   "id": "e7a8e8c7cde0665f",
   "metadata": {},
   "source": [
    "Считаем наш датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c41b35aa14d3d36",
   "metadata": {},
   "source": [
    "В качестве первого метода защиты добавим нормализацию входов в модель. Это уже должно будет снизить эффективность Adv. примеров, поскольку они существенно отличаются от нормальных примеров."
   ]
  },
  {
   "cell_type": "code",
   "id": "e265f7fbe01e8266",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T10:50:48.517714Z",
     "start_time": "2025-06-14T10:50:48.513851Z"
    }
   },
   "source": [
    "from art.preprocessing.standardisation_mean_std import StandardisationMeanStd\n",
    "\n",
    "norm_proc = StandardisationMeanStd(\n",
    "    mean=mean,\n",
    "    std =std\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 65
  },
  {
   "cell_type": "markdown",
   "id": "81ce71c0646429fe",
   "metadata": {},
   "source": [
    "Загрузим нашу уязвимую модель. Мы не будем обучать новую модель с нуля, вместо этого мы её дообучим"
   ]
  },
  {
   "cell_type": "code",
   "id": "132d6326fc63d55d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T12:44:09.159779Z",
     "start_time": "2025-06-14T12:44:09.155778Z"
    }
   },
   "source": [
    "class YoloClsAdapter(torch.nn.Module):\n",
    "    def __init__(self, core_model):\n",
    "        super().__init__()\n",
    "        self.core = core_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.core(x)\n",
    "        if isinstance(y, (tuple, list)):\n",
    "            y = y[-1]\n",
    "        return y"
   ],
   "outputs": [],
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "id": "666328e7bef43300",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T13:56:54.957341Z",
     "start_time": "2025-06-14T13:56:54.876945Z"
    }
   },
   "source": [
    "from ultralytics import YOLO\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "\n",
    "yolo  = YOLO(MODEL_PATH)\n",
    "for p in yolo.model.parameters():\n",
    "    p.requires_grad_(True)\n",
    "adapter = YoloClsAdapter(yolo.model).to(device)\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    adapter.parameters(),\n",
    "    lr=LR,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "classifier = PyTorchClassifier(\n",
    "    model=adapter,\n",
    "    loss=loss,\n",
    "    optimizer=optimizer,\n",
    "    nb_classes=10,\n",
    "    input_shape=(3, IMG_SIZE, IMG_SIZE),\n",
    "    clip_values=(0.0, 1.0),\n",
    "    device_type=device\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 95
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Считаем наш датасет (TODO: объяснить почему именно так)",
   "id": "8c3584cef8f3b23a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T12:44:18.778045Z",
     "start_time": "2025-06-14T12:44:18.771042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "import gc\n",
    "from itertools import islice\n",
    "\n",
    "class ChunkedGenerator:\n",
    "    def __init__(self, dir_path: Path, *, chunk, batch_size, shuffle):\n",
    "        self.dir         = dir_path\n",
    "        self.chunk       = chunk\n",
    "        self.batch_size  = batch_size\n",
    "        self.shuffle     = shuffle\n",
    "\n",
    "        self.files       = list(self.dir.glob(\"*/*.png\"))\n",
    "        self.size        = len(self.files)          # обязательное поле для ART\n",
    "\n",
    "        self._chunk_iter = None     # текущий генератор «порций»\n",
    "        self._batch_buf  = []       # накопленные (x,y) перед отдачей\n",
    "\n",
    "    @staticmethod\n",
    "    def _chunked_files(file_list, chunk):\n",
    "        \"\"\"yield списки путей по chunk штук\"\"\"\n",
    "        it = iter(file_list)\n",
    "        while (batch := list(islice(it, chunk))):\n",
    "            yield batch\n",
    "    # ----------------- helpers -----------------\n",
    "    def _reset_epochs(self):\n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.files)\n",
    "        self._chunk_iter = self._chunked_files(self.files, self.chunk)\n",
    "\n",
    "    def _load_next_chunk(self):\n",
    "        \"\"\"Загружает очередные ≤chunk файлов в RAM.\"\"\"\n",
    "        file_chunk = next(self._chunk_iter)           # StopIteration → обрабатывается выше\n",
    "\n",
    "        x_list, y_list = [], []\n",
    "        for fp in file_chunk:\n",
    "            img = Image.open(fp).convert(\"RGB\")\n",
    "            arr = yolo.model.transforms(img).numpy()  # float32, CHW, 0-1\n",
    "            x_list.append(arr)\n",
    "            y_list.append(int(fp.parent.name))\n",
    "\n",
    "        x_chunk = np.stack(x_list, axis=0)\n",
    "        y_chunk = np.asarray(y_list)\n",
    "\n",
    "        # разбиваем на mini-batch’и и кладём в буфер\n",
    "        for i in range(0, len(x_chunk), self.batch_size):\n",
    "            self._batch_buf.append((x_chunk[i:i + self.batch_size],\n",
    "                                    y_chunk[i:i + self.batch_size]))\n",
    "\n",
    "        # подчистить уже не нужные крупные массивы\n",
    "        del x_chunk, y_chunk, x_list, y_list, file_chunk\n",
    "        gc.collect()\n",
    "\n",
    "    # -------------- обязательный метод ART --------------\n",
    "    def get_batch(self):                      # ← именно его вызывает fit_generator()\n",
    "        if not self._batch_buf:               # буфер пуст — нужно загрузить новую «порцию»\n",
    "            if self._chunk_iter is None:\n",
    "                self._reset_epochs()          # первый вызов в эпоху\n",
    "            try:\n",
    "                self._load_next_chunk()\n",
    "            except StopIteration:             # прошли весь набор → начать новую эпоху\n",
    "                self._reset_epochs()\n",
    "                self._load_next_chunk()\n",
    "\n",
    "        return self._batch_buf.pop(0)\n",
    "\n",
    "    # -------------- опционально -----------------\n",
    "    def __iter__(self):       # чтобы можно было for-loop’ом\n",
    "        for _ in range(self.size // self.batch_size):\n",
    "            yield self.get_batch()"
   ],
   "id": "815502aee27f0cd4",
   "outputs": [],
   "execution_count": 80
  },
  {
   "cell_type": "markdown",
   "id": "4f40174e83a4104c",
   "metadata": {},
   "source": [
    "В качестве генератора Adversarial examples выберем даже более сильный метод, чем FGSM из предыдущей работы - ProjectedGradientDescent. Это обеспечит защиту как от более слабого метода, так и от некоторых более сильных"
   ]
  },
  {
   "cell_type": "code",
   "id": "328db6c63686c60e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T10:52:02.103776Z",
     "start_time": "2025-06-14T10:52:02.099770Z"
    }
   },
   "source": [
    "from art.attacks.evasion import ProjectedGradientDescent\n",
    "\n",
    "pgd_attack = ProjectedGradientDescent(\n",
    "    estimator=classifier,\n",
    "    norm=np.inf,\n",
    "    eps=EPS,\n",
    "    eps_step=EPS_STEP,\n",
    "    max_iter=MAX_PGD_ITERS,\n",
    "    targeted=False,\n",
    "    verbose=False\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 68
  },
  {
   "cell_type": "markdown",
   "id": "1369c19fb6208e01",
   "metadata": {},
   "source": [
    "Наконец, создадим наш класс для адверсариального обучения и дообучим нашу модель на 10 эпохах"
   ]
  },
  {
   "cell_type": "code",
   "id": "afc822c6bb08b16f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T16:52:58.046248Z",
     "start_time": "2025-06-14T16:52:49.718140Z"
    }
   },
   "source": [
    "from art.defences.trainer import AdversarialTrainerFBFPyTorch\n",
    "\n",
    "CHUNK = 5_000\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS     = 5\n",
    "SHUFFLE_DS = False\n",
    "\n",
    "train_gen = ChunkedGenerator(\n",
    "    DATA_DIR / \"train\",\n",
    "    chunk=CHUNK,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=SHUFFLE_DS,\n",
    ")\n",
    "\n",
    "adv_trainer = AdversarialTrainerFBFPyTorch(\n",
    "    classifier\n",
    ")\n",
    "\n",
    "adv_trainer.fit_generator(        # !!\n",
    "    generator=train_gen,          # функция, порождающая генератор на каждый epoch\n",
    "    nb_epochs=EPOCHS\n",
    ")\n",
    "\n",
    "robust_classifier = adv_trainer.get_classifier()\n",
    "robust_classifier.save('robust_classifier6.pt', 'models')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adversarial Training FBF - Epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "524ce3ad87fe41e4a585e982ed6a08fe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mIndexError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[109]\u001B[39m\u001B[32m, line 20\u001B[39m\n\u001B[32m      9\u001B[39m train_gen = ChunkedGenerator(\n\u001B[32m     10\u001B[39m     DATA_DIR / \u001B[33m\"\u001B[39m\u001B[33mtrain\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     11\u001B[39m     chunk=CHUNK,\n\u001B[32m     12\u001B[39m     batch_size=BATCH_SIZE,\n\u001B[32m     13\u001B[39m     shuffle=SHUFFLE_DS,\n\u001B[32m     14\u001B[39m )\n\u001B[32m     16\u001B[39m adv_trainer = AdversarialTrainerFBFPyTorch(\n\u001B[32m     17\u001B[39m     classifier\n\u001B[32m     18\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m20\u001B[39m \u001B[43madv_trainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit_generator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# !!\u001B[39;49;00m\n\u001B[32m     21\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgenerator\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrain_gen\u001B[49m\u001B[43m,\u001B[49m\u001B[43m          \u001B[49m\u001B[38;5;66;43;03m# функция, порождающая генератор на каждый epoch\u001B[39;49;00m\n\u001B[32m     22\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnb_epochs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mEPOCHS\u001B[49m\n\u001B[32m     23\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m     25\u001B[39m robust_classifier = adv_trainer.get_classifier()\n\u001B[32m     26\u001B[39m robust_classifier.save(\u001B[33m'\u001B[39m\u001B[33mrobust_classifier6.pt\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mmodels\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\art\\defences\\trainer\\adversarial_trainer_fbf_pytorch.py:181\u001B[39m, in \u001B[36mAdversarialTrainerFBFPyTorch.fit_generator\u001B[39m\u001B[34m(self, generator, nb_epochs, **kwargs)\u001B[39m\n\u001B[32m    178\u001B[39m x_batch, y_batch = generator.get_batch()\n\u001B[32m    179\u001B[39m x_batch = x_batch.copy()\n\u001B[32m--> \u001B[39m\u001B[32m181\u001B[39m _train_loss, _train_acc, _train_n = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_batch_process\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ml_r\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    183\u001B[39m train_loss += _train_loss\n\u001B[32m    184\u001B[39m train_acc += _train_acc\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\art\\defences\\trainer\\adversarial_trainer_fbf_pytorch.py:214\u001B[39m, in \u001B[36mAdversarialTrainerFBFPyTorch._batch_process\u001B[39m\u001B[34m(self, x_batch, y_batch, l_r)\u001B[39m\n\u001B[32m    212\u001B[39m m = np.prod(x_batch.shape[\u001B[32m1\u001B[39m:]).item()\n\u001B[32m    213\u001B[39m delta = random_sphere(n, m, \u001B[38;5;28mself\u001B[39m._eps, np.inf).reshape(x_batch.shape).astype(ART_NUMPY_DTYPE)\n\u001B[32m--> \u001B[39m\u001B[32m214\u001B[39m delta_grad = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_classifier\u001B[49m\u001B[43m.\u001B[49m\u001B[43mloss_gradient\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_batch\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[43mdelta\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    215\u001B[39m delta = np.clip(delta + \u001B[32m1.25\u001B[39m * \u001B[38;5;28mself\u001B[39m._eps * np.sign(delta_grad), -\u001B[38;5;28mself\u001B[39m._eps, +\u001B[38;5;28mself\u001B[39m._eps)\n\u001B[32m    216\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._classifier.clip_values \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\art\\estimators\\classification\\pytorch.py:834\u001B[39m, in \u001B[36mPyTorchClassifier.loss_gradient\u001B[39m\u001B[34m(self, x, y, training_mode, **kwargs)\u001B[39m\n\u001B[32m    831\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mCombination of inputs and preprocessing not supported.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    833\u001B[39m \u001B[38;5;66;03m# Check label shape\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m834\u001B[39m y_preprocessed = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mreduce_labels\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_preprocessed\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    836\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(y_preprocessed, np.ndarray):\n\u001B[32m    837\u001B[39m     labels_t = torch.from_numpy(y_preprocessed).to(\u001B[38;5;28mself\u001B[39m._device)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\art\\estimators\\classification\\pytorch.py:285\u001B[39m, in \u001B[36mPyTorchClassifier.reduce_labels\u001B[39m\u001B[34m(self, y)\u001B[39m\n\u001B[32m    283\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._reduce_labels \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._int_labels:\n\u001B[32m    284\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(y, torch.Tensor):\n\u001B[32m--> \u001B[39m\u001B[32m285\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43margmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    286\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m np.argmax(y, axis=\u001B[32m1\u001B[39m)\n\u001B[32m    287\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._reduce_labels:  \u001B[38;5;66;03m# float labels\u001B[39;00m\n",
      "\u001B[31mIndexError\u001B[39m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "execution_count": 109
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Сохраним обученную модель",
   "id": "bbb4b619730c14d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T23:10:36.131300Z",
     "start_time": "2025-06-13T23:10:35.964654Z"
    }
   },
   "cell_type": "code",
   "source": "robust_classifier.save('robust_classifier2.pt', 'models')",
   "id": "f9ddd626021f542a",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T09:31:10.978759Z",
     "start_time": "2025-06-14T09:31:10.881819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = torch.load('models/robust_classifier2.pt.model')\n",
    "data.keys"
   ],
   "id": "fb0439ff90faa2e7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function OrderedDict.keys>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T09:39:22.084207Z",
     "start_time": "2025-06-14T09:39:21.939910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "yolo = YOLO(MODEL_PATH)\n",
    "adapter = YoloClsAdapter(yolo.model).to(device)\n",
    "adapter.load_state_dict(torch.load('models/robust_classifier2.pt.model'))\n",
    "robust_classifier = PyTorchClassifier(\n",
    "    model=adapter,\n",
    "    loss=torch.nn.CrossEntropyLoss(),\n",
    "    nb_classes=10,\n",
    "    input_shape=(3, IMG_SIZE, IMG_SIZE),\n",
    "    clip_values=(0.0, 1.0),\n",
    "    device_type=device\n",
    ")"
   ],
   "id": "4e728f1ca508233a",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Теперь сравним качество изначальной и дообученной моделей как на чистой, так и на adv. выборках",
   "id": "eb89aca0c8aa1571"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T08:50:13.832865Z",
     "start_time": "2025-06-14T08:50:13.780994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from art.estimators.classification import PyTorchClassifier\n",
    "\n",
    "basic_yolo  = YOLO(MODEL_PATH)\n",
    "adapter = YoloClsAdapter(basic_yolo.model).to(device).eval()\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "basic_cls = PyTorchClassifier(\n",
    "    model=adapter,\n",
    "    loss=loss,\n",
    "    nb_classes=10,\n",
    "    input_shape=(3, IMG_SIZE, IMG_SIZE),\n",
    "    clip_values=(0.0, 1.0),\n",
    "    device_type=device\n",
    ")"
   ],
   "id": "6ed993476e1969b4",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T16:49:21.118133Z",
     "start_time": "2025-06-14T16:49:19.408672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "\n",
    "N_SAMPLES = 1000\n",
    "\n",
    "all_files = list((DATA_DIR / 'test').glob(\"*/*.png\"))\n",
    "assert all_files, f\"Ничего не найдено в {DATA_DIR}\"\n",
    "\n",
    "idx_files = random.sample(all_files, N_SAMPLES) # Выбираем N_SAMPLES картинок\n",
    "\n",
    "x, y = [], []\n",
    "for fp in idx_files:\n",
    "    img = Image.open(fp).convert(\"RGB\")\n",
    "    arr = basic_yolo.model.transforms(img)\n",
    "    x.append(arr)\n",
    "    y.append(int(fp.parent.name))\n",
    "\n",
    "clean_x = np.stack(x, axis=0)\n",
    "clean_y = np.asarray(y)\n",
    "clean_y"
   ],
   "id": "22029ee8158fea04",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 3, 2, 3, 2, 1, 9, 8, 8, 5, 7, 2, 1, 0, 2, 3, 9, 3, 2, 5, 2, 7, 7, 8, 3, 1, 5, 1, 1, 9, 1, 1, 8, 5, 5, 7, 2, 2, 5, 1, 8, 7, 1, 2, 3, 1, 5, 4, 7, 6, 1, 7, 3, 5, 3, 0, 4, 3, 5, 0, 9, 8, 3, 0, 4, 3, 6, 9, 0, 3, 2, 1, 5, 2, 2, 5, 3, 1, 2, 1, 9, 2, 1, 9, 6, 5, 5, 5, 1, 2, 7, 2, 3, 2, 1, 2, 1, 6, 6, 9, 2, 2, 0, 0,\n",
       "       9, 3, 0, 4, 8, 2, 4, 6, 1, 8, 1, 2, 2, 1, 9, 8, 4, 0, 6, 5, 5, 7, 1, 3, 4, 8, 6, 3, 1, 1, 2, 1, 7, 1, 2, 0, 5, 2, 2, 2, 0, 1, 3, 1, 7, 9, 2, 2, 7, 3, 4, 5, 1, 5, 7, 2, 2, 5, 2, 6, 1, 2, 0, 8, 4, 6, 3, 4, 2, 5, 3, 5, 6, 4, 1, 4, 9, 2, 2, 4, 2, 1, 3, 6, 0, 8, 6, 5, 5, 3, 1, 2, 6, 1, 5, 2, 6, 2, 3, 1, 9, 2, 2, 4,\n",
       "       3, 4, 6, 1, 5, 1, 5, 0, 1, 6, 8, 9, 1, 4, 4, 4, 5, 1, 5, 5, 4, 4, 0, 2, 2, 1, 0, 4, 3, 9, 2, 0, 2, 1, 5, 7, 8, 0, 0, 1, 4, 8, 2, 6, 1, 9, 1, 9, 0, 4, 5, 9, 2, 7, 0, 3, 9, 1, 4, 1, 8, 5, 1, 1, 5, 2, 2, 3, 3, 5, 6, 3, 3, 0, 5, 9, 3, 1, 9, 9, 9, 0, 6, 8, 2, 2, 2, 1, 2, 1, 5, 2, 4, 2, 4, 1, 2, 2, 1, 7, 3, 2, 7, 1,\n",
       "       4, 3, 1, 2, 5, 9, 5, 1, 9, 2, 1, 4, 4, 5, 3, 9, 5, 6, 9, 1, 7, 5, 1, 1, 6, 5, 2, 4, 2, 3, 1, 6, 2, 1, 8, 2, 4, 5, 2, 5, 9, 4, 9, 5, 1, 2, 2, 4, 2, 5, 1, 3, 0, 7, 1, 2, 4, 1, 4, 1, 5, 3, 2, 1, 1, 2, 1, 2, 3, 9, 4, 2, 1, 1, 8, 2, 2, 3, 2, 6, 5, 6, 1, 4, 1, 9, 7, 6, 9, 9, 2, 2, 2, 2, 5, 3, 8, 4, 3, 2, 1, 2, 3, 7,\n",
       "       1, 2, 0, 0, 5, 6, 1, 3, 7, 7, 4, 3, 3, 6, 2, 7, 2, 4, 9, 1, 3, 2, 1, 1, 3, 8, 8, 1, 2, 9, 6, 3, 1, 4, 7, 1, 3, 8, 5, 9, 1, 6, 4, 8, 4, 7, 1, 1, 2, 4, 9, 3, 2, 7, 3, 3, 4, 2, 7, 2, 2, 3, 2, 1, 4, 0, 4, 1, 3, 7, 4, 1, 1, 4, 0, 2, 4, 1, 1, 1, 2, 1, 0, 1, 2, 4, 1, 1, 2, 6, 7, 2, 5, 2, 7, 5, 2, 5, 0, 9, 7, 0, 8, 5,\n",
       "       2, 5, 6, 1, 8, 1, 2, 2, 6, 3, 4, 2, 9, 5, 1, 0, 3, 3, 4, 4, 2, 9, 4, 3, 2, 0, 6, 1, 3, 5, 9, 1, 3, 1, 6, 5, 1, 0, 8, 3, 1, 7, 8, 4, 1, 7, 1, 5, 4, 0, 7, 2, 0, 6, 1, 9, 1, 1, 4, 2, 2, 9, 7, 2, 2, 6, 2, 5, 0, 4, 1, 3, 0, 7, 4, 1, 2, 5, 9, 2, 8, 4, 9, 1, 4, 1, 5, 7, 4, 2, 6, 1, 8, 6, 7, 1, 9, 1, 7, 2, 7, 0, 1, 5,\n",
       "       7, 1, 2, 9, 3, 9, 1, 1, 9, 3, 1, 4, 5, 3, 3, 9, 7, 6, 2, 5, 8, 3, 6, 1, 9, 8, 2, 2, 2, 7, 2, 4, 2, 9, 2, 6, 1, 1, 9, 5, 4, 1, 4, 4, 3, 4, 6, 0, 1, 1, 2, 0, 2, 0, 2, 8, 3, 4, 3, 8, 0, 5, 5, 5, 9, 0, 0, 6, 5, 9, 2, 8, 6, 9, 1, 9, 3, 6, 6, 7, 2, 6, 2, 2, 5, 4, 1, 1, 0, 1, 4, 5, 1, 8, 4, 6, 0, 0, 1, 3, 3, 7, 8, 3,\n",
       "       1, 2, 1, 1, 1, 8, 0, 6, 2, 1, 2, 3, 8, 3, 2, 8, 8, 4, 4, 1, 1, 1, 2, 4, 1, 2, 5, 8, 6, 2, 2, 4, 2, 5, 3, 0, 4, 2, 9, 1, 5, 2, 2, 1, 0, 3, 1, 8, 0, 3, 9, 2, 2, 2, 5, 1, 1, 6, 6, 0, 4, 0, 8, 9, 7, 4, 3, 3, 2, 5, 5, 4, 1, 0, 1, 1, 6, 1, 2, 9, 6, 3, 7, 0, 1, 2, 1, 2, 8, 1, 8, 3, 2, 4, 2, 5, 4, 2, 7, 8, 6, 8, 3, 2,\n",
       "       1, 5, 6, 4, 2, 4, 5, 2, 6, 1, 8, 9, 9, 5, 9, 2, 1, 2, 0, 0, 8, 2, 9, 1, 1, 3, 1, 4, 2, 1, 9, 3, 1, 4, 6, 4, 2, 1, 4, 4, 2, 6, 2, 3, 0, 9, 2, 5, 1, 9, 5, 7, 1, 3, 6, 2, 4, 2, 6, 2, 5, 1, 3, 4, 7, 2, 9, 2, 2, 1, 8, 4, 2, 4, 3, 7, 0, 5, 9, 1, 3, 7, 3, 0, 2, 8, 4, 2, 1, 6, 7, 7, 2, 5, 3, 8, 2, 7, 2, 0, 2, 0, 4, 1,\n",
       "       9, 4, 0, 3, 7, 8, 3, 6, 2, 9, 6, 7, 2, 2, 5, 2, 5, 5, 1, 0, 2, 6, 3, 8, 6, 8, 2, 5, 1, 7, 4, 0, 1, 6, 9, 6, 3, 0, 1, 2, 5, 2, 5, 8, 2, 5, 0, 3, 3, 1, 2, 9, 8, 7, 8, 6, 2, 7, 5, 5, 3, 6, 2, 6])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T09:33:34.936736Z",
     "start_time": "2025-06-14T09:33:24.523640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from art.attacks.evasion import FastGradientMethod\n",
    "\n",
    "EPS = 8/255\n",
    "\n",
    "# Генерируем FGSM по изначальной модели\n",
    "basic_fgsm = FastGradientMethod(estimator=basic_cls, eps=EPS)\n",
    "basic_x_fgsm  = basic_fgsm.generate(x=clean_x)\n",
    "\n",
    "# FGSM по защищённой модели\n",
    "robust_fgsm = FastGradientMethod(estimator=robust_classifier, eps=EPS)\n",
    "robust_x_fgsm  = basic_fgsm.generate(x=clean_x)"
   ],
   "id": "c5542e50479de86d",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T16:46:54.132289Z",
     "start_time": "2025-06-14T16:46:52.235825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_gen = ChunkedGenerator(\n",
    "    DATA_DIR / \"test\",\n",
    "    chunk=1000,\n",
    "    batch_size=1000,\n",
    "    shuffle=False,\n",
    ")\n",
    "x, y = train_gen.get_batch()"
   ],
   "id": "98d9e655df75266a",
   "outputs": [],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T16:47:39.568813Z",
     "start_time": "2025-06-14T16:47:38.550071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y, robust_classifier.predict(x).argmax(1))"
   ],
   "id": "9ae348290692a986",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T16:46:14.538395Z",
     "start_time": "2025-06-14T16:46:07.971661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ❶ Cводим всё в словари --------------------------------------------------------\n",
    "tests   = dict(  # порядок сохранится как объявлен\n",
    "    clean_train   = clean_x,\n",
    "    basic_x_fgsm  = basic_x_fgsm,\n",
    "    robust_x_fgsm = robust_x_fgsm\n",
    ")\n",
    "models  = dict(basic = basic_cls, robust = robust_classifier)\n",
    "\n",
    "# ❷ Предсказания всех (model × test) за один проход ----------------------------\n",
    "preds = {\n",
    "    (m, t): mdl.predict(x).argmax(1)          # argmax → метки классов\n",
    "    for m, mdl in models.items()\n",
    "    for t, x   in tests.items()\n",
    "}\n",
    "\n",
    "cols = [\"basic_accuracy\", \"basic_ASR\", \"robust_accuracy\", \"robust_ASR\"]\n",
    "df = pd.DataFrame(index=tests, columns=cols, dtype=\"float32\")\n",
    "\n",
    "for m in models:\n",
    "    clean_pred = preds[(m, \"clean_train\")]\n",
    "    acc_col = f\"{m}_accuracy\"\n",
    "    asr_col = f\"{m}_ASR\"\n",
    "\n",
    "    for t in tests:\n",
    "        adv_pred = preds[(m, t)]\n",
    "        accuracy = np.mean(adv_pred == clean_y)\n",
    "        if t == \"clean_train\":\n",
    "            asr = 0\n",
    "        else:\n",
    "            asr = np.mean((clean_pred == clean_y) & (adv_pred != clean_y))\n",
    "\n",
    "        df.at[t, acc_col] = accuracy\n",
    "        df.at[t, asr_col] = asr\n",
    "\n",
    "df"
   ],
   "id": "2e7dee92aa45c1e7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ok__\\AppData\\Local\\Temp\\ipykernel_19856\\1630435535.py:34: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.965' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  df.at[t, acc_col] = accuracy\n",
      "C:\\Users\\ok__\\AppData\\Local\\Temp\\ipykernel_19856\\1630435535.py:35: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.796' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  df.at[t, asr_col] = asr\n",
      "C:\\Users\\ok__\\AppData\\Local\\Temp\\ipykernel_19856\\1630435535.py:34: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.074' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  df.at[t, acc_col] = accuracy\n",
      "C:\\Users\\ok__\\AppData\\Local\\Temp\\ipykernel_19856\\1630435535.py:35: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.007' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  df.at[t, asr_col] = asr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "               basic_accuracy  basic_ASR  robust_accuracy  robust_ASR\n",
       "clean_train             0.965      0.000            0.074       0.000\n",
       "basic_x_fgsm            0.171      0.796            0.068       0.007\n",
       "robust_x_fgsm           0.171      0.796            0.068       0.007"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>basic_accuracy</th>\n",
       "      <th>basic_ASR</th>\n",
       "      <th>robust_accuracy</th>\n",
       "      <th>robust_ASR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clean_train</th>\n",
       "      <td>0.965</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basic_x_fgsm</th>\n",
       "      <td>0.171</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robust_x_fgsm</th>\n",
       "      <td>0.171</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 99
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
