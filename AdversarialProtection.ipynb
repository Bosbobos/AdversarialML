{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cddf8587116c0f",
   "metadata": {},
   "source": [
    "# Защита модели от Adversarial примеров\n",
    "\n",
    "Работа выполнена студентом БИБ233 МИЭМ НИУ ВШЭ Коноваловым Матвеем.\n",
    "\n",
    "Данная работа является продолжением предыдущей, в которой рассматривалось создание Adversarial примеров в задаче классификации изображений.\n",
    "\n",
    "Атака оказалась крайне удачной, и в ходе данной работы будут рассмотрены способы это исправить.\n",
    "\n",
    "## Основные способы защиты, рассмотренные в работе:\n",
    "- Adversarial training\n",
    "- нормализация входных данных\n",
    "- использование небольшого dropout\n",
    "\n",
    "Все эти изменения будут вноситься при помощи библиотеки Adversarial Robustness Toolbox."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b925fd6341e2c4e",
   "metadata": {},
   "source": [
    "Зададим все необходимые параметры. В MODEL_PATH укажите, куда вы положили [обученную модель из предыдущего пункта](https://disk.360.yandex.ru/d/r-5SqYBdwTfuuQ)"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2025-06-14T08:43:46.670207Z",
     "start_time": "2025-06-14T08:43:41.132776Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "IMG_SIZE = 224\n",
    "MODEL_PATH = Path('models/best.pt')\n",
    "DATA_DIR = Path(\"datasets/svhn_cls\")\n",
    "mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "std = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "LR = 1e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "EPS = 0.03\n",
    "EPS_STEP = 0.007\n",
    "BETA = 6\n",
    "MAX_PGD_ITERS = 3\n",
    "SEED = 17\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "e7a8e8c7cde0665f",
   "metadata": {},
   "source": [
    "Считаем наш датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c41b35aa14d3d36",
   "metadata": {},
   "source": [
    "В качестве первого метода защиты добавим нормализацию входов в модель. Это уже должно будет снизить эффективность Adv. примеров, поскольку они существенно отличаются от нормальных примеров."
   ]
  },
  {
   "cell_type": "code",
   "id": "e265f7fbe01e8266",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T08:50:00.414131Z",
     "start_time": "2025-06-14T08:50:00.410627Z"
    }
   },
   "source": [
    "from art.preprocessing.standardisation_mean_std import StandardisationMeanStd\n",
    "\n",
    "norm_proc = StandardisationMeanStd(\n",
    "    mean=mean,\n",
    "    std =std\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "81ce71c0646429fe",
   "metadata": {},
   "source": [
    "Загрузим нашу уязвимую модель. Мы не будем обучать новую модель с нуля, вместо этого мы её дообучим"
   ]
  },
  {
   "cell_type": "code",
   "id": "132d6326fc63d55d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T08:45:06.066685Z",
     "start_time": "2025-06-14T08:45:06.062672Z"
    }
   },
   "source": [
    "class YoloClsAdapter(torch.nn.Module):\n",
    "    def __init__(self, core_model):\n",
    "        super().__init__()\n",
    "        self.core = core_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.core(x)\n",
    "        if isinstance(out, (tuple, list)):\n",
    "            out = out[1] if self.training and len(out) == 2 else out[0]\n",
    "        return out"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "666328e7bef43300",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T16:30:28.202407Z",
     "start_time": "2025-06-13T16:30:27.173771Z"
    }
   },
   "source": [
    "from ultralytics import YOLO\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "\n",
    "yolo  = YOLO(MODEL_PATH)\n",
    "for p in yolo.model.parameters():\n",
    "    p.requires_grad_(True)\n",
    "adapter = YoloClsAdapter(yolo.model).to(device)\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    adapter.parameters(),\n",
    "    lr=LR,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "classifier = PyTorchClassifier(\n",
    "    model=adapter,\n",
    "    loss=loss,\n",
    "    optimizer=optimizer,\n",
    "    nb_classes=10,\n",
    "    input_shape=(3, IMG_SIZE, IMG_SIZE),\n",
    "    clip_values=(0.0, 1.0),\n",
    "    preprocessing_defences=[norm_proc],\n",
    "    device_type=device\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Считаем наш датасет (TODO: объяснить почему именно так)",
   "id": "8c3584cef8f3b23a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T09:46:47.657201Z",
     "start_time": "2025-06-14T09:46:47.649801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "import gc\n",
    "from itertools import islice\n",
    "\n",
    "class ChunkedGenerator:\n",
    "    def __init__(self, dir_path: Path, *, chunk, batch_size, shuffle):\n",
    "        self.dir         = dir_path\n",
    "        self.chunk       = chunk\n",
    "        self.batch_size  = batch_size\n",
    "        self.shuffle     = shuffle\n",
    "\n",
    "        self.files       = list(self.dir.glob(\"*/*.png\"))\n",
    "        self.size        = len(self.files)          # обязательное поле для ART\n",
    "\n",
    "        self._chunk_iter = None     # текущий генератор «порций»\n",
    "        self._batch_buf  = []       # накопленные (x,y) перед отдачей\n",
    "\n",
    "    @staticmethod\n",
    "    def _chunked_files(file_list, chunk):\n",
    "        \"\"\"yield списки путей по chunk штук\"\"\"\n",
    "        it = iter(file_list)\n",
    "        while (batch := list(islice(it, chunk))):\n",
    "            yield batch\n",
    "    # ----------------- helpers -----------------\n",
    "    def _reset_epochs(self):\n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.files)\n",
    "        self._chunk_iter = self._chunked_files(self.files, self.chunk)\n",
    "\n",
    "    def _load_next_chunk(self):\n",
    "        \"\"\"Загружает очередные ≤chunk файлов в RAM.\"\"\"\n",
    "        file_chunk = next(self._chunk_iter)           # StopIteration → обрабатывается выше\n",
    "\n",
    "        x_list, y_list = [], []\n",
    "        for fp in file_chunk:\n",
    "            img = Image.open(fp).convert(\"RGB\")\n",
    "            arr = yolo.model.transforms(img).numpy()  # float32, CHW, 0-1\n",
    "            x_list.append(arr)\n",
    "            y_list.append(int(fp.parent.name))\n",
    "\n",
    "        x_chunk = np.stack(x_list, axis=0)\n",
    "        y_chunk = np.asarray(y_list)\n",
    "\n",
    "        # разбиваем на mini-batch’и и кладём в буфер\n",
    "        for i in range(0, len(x_chunk), self.batch_size):\n",
    "            self._batch_buf.append((x_chunk[i:i + self.batch_size],\n",
    "                                    y_chunk[i:i + self.batch_size]))\n",
    "\n",
    "        # подчистить уже не нужные крупные массивы\n",
    "        del x_chunk, y_chunk, x_list, y_list, file_chunk\n",
    "        gc.collect()\n",
    "\n",
    "    # -------------- обязательный метод ART --------------\n",
    "    def get_batch(self):                      # ← именно его вызывает fit_generator()\n",
    "        if not self._batch_buf:               # буфер пуст — нужно загрузить новую «порцию»\n",
    "            if self._chunk_iter is None:\n",
    "                self._reset_epochs()          # первый вызов в эпоху\n",
    "            try:\n",
    "                self._load_next_chunk()\n",
    "            except StopIteration:             # прошли весь набор → начать новую эпоху\n",
    "                self._reset_epochs()\n",
    "                self._load_next_chunk()\n",
    "\n",
    "        return self._batch_buf.pop(0)\n",
    "\n",
    "    # -------------- опционально -----------------\n",
    "    def __iter__(self):       # чтобы можно было for-loop’ом\n",
    "        for _ in range(self.size // self.batch_size):\n",
    "            yield self.get_batch()"
   ],
   "id": "815502aee27f0cd4",
   "outputs": [],
   "execution_count": 60
  },
  {
   "cell_type": "markdown",
   "id": "4f40174e83a4104c",
   "metadata": {},
   "source": [
    "В качестве генератора Adversarial examples выберем даже более сильный метод, чем FGSM из предыдущей работы - ProjectedGradientDescent. Это обеспечит защиту как от более слабого метода, так и от некоторых более сильных"
   ]
  },
  {
   "cell_type": "code",
   "id": "328db6c63686c60e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T16:30:28.297326Z",
     "start_time": "2025-06-13T16:30:28.293755Z"
    }
   },
   "source": [
    "from art.attacks.evasion import ProjectedGradientDescent\n",
    "\n",
    "pgd_attack = ProjectedGradientDescent(\n",
    "    estimator=classifier,\n",
    "    norm=np.inf,\n",
    "    eps=EPS,\n",
    "    eps_step=EPS_STEP,\n",
    "    max_iter=MAX_PGD_ITERS,\n",
    "    targeted=False,\n",
    "    verbose=False\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "1369c19fb6208e01",
   "metadata": {},
   "source": [
    "Наконец, создадим наш класс для адверсариального обучения и дообучим нашу модель на 10 эпохах"
   ]
  },
  {
   "cell_type": "code",
   "id": "afc822c6bb08b16f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T20:43:50.322704Z",
     "start_time": "2025-06-13T16:38:08.290552Z"
    }
   },
   "source": [
    "from art.defences.trainer import AdversarialTrainerTRADESPyTorch\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "\n",
    "CHUNK = 5_000\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS     = 5\n",
    "SHUFFLE_DS = False\n",
    "\n",
    "train_gen = ChunkedGenerator(\n",
    "    DATA_DIR / \"train\",\n",
    "    chunk=CHUNK,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=SHUFFLE_DS,\n",
    ")\n",
    "\n",
    "adv_trainer = AdversarialTrainerTRADESPyTorch(\n",
    "    classifier,\n",
    "    attack=FastGradientMethod(estimator=classifier, eps=EPS),\n",
    "    beta=BETA\n",
    ")\n",
    "\n",
    "adv_trainer.fit_generator(        # !!\n",
    "    generator=train_gen,          # функция, порождающая генератор на каждый epoch\n",
    "    nb_epochs=EPOCHS\n",
    ")\n",
    "\n",
    "robust_classifier = adv_trainer.get_classifier()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adversarial Training TRADES - Epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "61d98d1e266946e3be4eda0820ffcab8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Сохраним обученную модель",
   "id": "bbb4b619730c14d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T23:10:36.131300Z",
     "start_time": "2025-06-13T23:10:35.964654Z"
    }
   },
   "cell_type": "code",
   "source": "robust_classifier.save('robust_classifier2.pt', 'models')",
   "id": "f9ddd626021f542a",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T09:31:10.978759Z",
     "start_time": "2025-06-14T09:31:10.881819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = torch.load('models/robust_classifier2.pt.model')\n",
    "data.keys"
   ],
   "id": "fb0439ff90faa2e7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function OrderedDict.keys>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T09:39:22.084207Z",
     "start_time": "2025-06-14T09:39:21.939910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "yolo = YOLO(MODEL_PATH)\n",
    "adapter = YoloClsAdapter(yolo.model).to(device)\n",
    "adapter.load_state_dict(torch.load('models/robust_classifier2.pt.model'))\n",
    "robust_classifier = PyTorchClassifier(\n",
    "    model=adapter,\n",
    "    loss=torch.nn.CrossEntropyLoss(),\n",
    "    nb_classes=10,\n",
    "    input_shape=(3, IMG_SIZE, IMG_SIZE),\n",
    "    clip_values=(0.0, 1.0),\n",
    "    device_type=device\n",
    ")"
   ],
   "id": "4e728f1ca508233a",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Теперь сравним качество изначальной и дообученной моделей как на чистой, так и на adv. выборках",
   "id": "eb89aca0c8aa1571"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T08:50:09.474940Z",
     "start_time": "2025-06-14T08:50:09.470107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def eval_clean(clf, x, y, batch=32):\n",
    "    preds = clf.predict(x, batch_size=batch).argmax(1)\n",
    "    return accuracy_score(y, preds)\n",
    "\n",
    "def eval_adv_pgd(clf, x, y,\n",
    "                 eps=0.03, eps_step=0.007, n_iter=10,\n",
    "                 batch=32, rand_init=True):\n",
    "    pgd = ProjectedGradientDescent(\n",
    "        estimator=clf, norm=np.inf,\n",
    "        eps=eps, eps_step=eps_step, max_iter=n_iter,\n",
    "        num_random_init=1 if rand_init else 0, targeted=False, verbose=False\n",
    "    )\n",
    "    x_adv = pgd.generate(x=x, batch_size=batch)\n",
    "\n",
    "    y_pred_clean = clf.predict(x,      batch_size=batch).argmax(1)\n",
    "    y_pred_adv   = clf.predict(x_adv,  batch_size=batch).argmax(1)\n",
    "\n",
    "    clean_correct = y_pred_clean == y\n",
    "    adv_correct   = y_pred_adv   == y\n",
    "\n",
    "    clean_acc = clean_correct.mean()\n",
    "    adv_acc   = adv_correct.mean()\n",
    "    asr       = (clean_correct & ~adv_correct).sum() / clean_correct.sum()\n",
    "    return clean_acc, adv_acc, asr"
   ],
   "id": "103b73ddbc9dda8f",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T08:50:13.832865Z",
     "start_time": "2025-06-14T08:50:13.780994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from art.estimators.classification import PyTorchClassifier\n",
    "\n",
    "basic_yolo  = YOLO(MODEL_PATH)\n",
    "adapter = YoloClsAdapter(basic_yolo.model).to(device).eval()\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "basic_cls = PyTorchClassifier(\n",
    "    model=adapter,\n",
    "    loss=loss,\n",
    "    nb_classes=10,\n",
    "    input_shape=(3, IMG_SIZE, IMG_SIZE),\n",
    "    clip_values=(0.0, 1.0),\n",
    "    device_type=device\n",
    ")"
   ],
   "id": "6ed993476e1969b4",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T09:45:43.169245Z",
     "start_time": "2025-06-14T09:45:41.657474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "\n",
    "N_SAMPLES = 1000\n",
    "\n",
    "all_files = list((DATA_DIR / 'test').glob(\"*/*.png\"))\n",
    "assert all_files, f\"Ничего не найдено в {DATA_DIR}\"\n",
    "\n",
    "idx_files = random.sample(all_files, N_SAMPLES) # Выбираем N_SAMPLES картинок\n",
    "\n",
    "x, y = [], []\n",
    "for fp in idx_files:\n",
    "    img = Image.open(fp).convert(\"RGB\")\n",
    "    arr = basic_yolo.model.transforms(img)\n",
    "    x.append(arr)\n",
    "    y.append(int(fp.parent.name))\n",
    "\n",
    "clean_x = np.stack(x, axis=0)\n",
    "clean_y = np.asarray(y)"
   ],
   "id": "22029ee8158fea04",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T09:33:34.936736Z",
     "start_time": "2025-06-14T09:33:24.523640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from art.attacks.evasion import FastGradientMethod\n",
    "\n",
    "EPS = 8/255\n",
    "\n",
    "# Генерируем FGSM по изначальной модели\n",
    "basic_fgsm = FastGradientMethod(estimator=basic_cls, eps=EPS)\n",
    "basic_x_fgsm  = basic_fgsm.generate(x=clean_x)\n",
    "\n",
    "# FGSM по защищённой модели\n",
    "robust_fgsm = FastGradientMethod(estimator=robust_classifier, eps=EPS)\n",
    "robust_x_fgsm  = basic_fgsm.generate(x=clean_x)"
   ],
   "id": "c5542e50479de86d",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T09:46:55.587774Z",
     "start_time": "2025-06-14T09:46:54.114070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_gen = ChunkedGenerator(\n",
    "    DATA_DIR / \"test\",\n",
    "    chunk=1000,\n",
    "    batch_size=1000,\n",
    "    shuffle=False,\n",
    ")\n",
    "x, y = train_gen.get_batch()"
   ],
   "id": "98d9e655df75266a",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T09:47:24.657080Z",
     "start_time": "2025-06-14T09:47:23.805540Z"
    }
   },
   "cell_type": "code",
   "source": "accuracy_score(y, basic_cls.predict(x).argmax(1))",
   "id": "9ae348290692a986",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.977"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T09:36:54.471238Z",
     "start_time": "2025-06-14T09:36:49.087509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ❶ Cводим всё в словари --------------------------------------------------------\n",
    "tests   = dict(  # порядок сохранится как объявлен\n",
    "    clean_train   = clean_x,\n",
    "    basic_x_fgsm  = basic_x_fgsm,\n",
    "    robust_x_fgsm = robust_x_fgsm\n",
    ")\n",
    "models  = dict(basic = basic_cls, robust = robust_classifier)\n",
    "\n",
    "# ❷ Предсказания всех (model × test) за один проход ----------------------------\n",
    "preds = {\n",
    "    (m, t): mdl.predict(x).argmax(1)          # argmax → метки классов\n",
    "    for m, mdl in models.items()\n",
    "    for t, x   in tests.items()\n",
    "}\n",
    "\n",
    "cols = [\"basic_accuracy\", \"basic_ASR\", \"robust_accuracy\", \"robust_ASR\"]\n",
    "df = pd.DataFrame(index=tests, columns=cols, dtype=\"float32\")\n",
    "\n",
    "for m in models:\n",
    "    clean_pred = preds[(m, \"clean_train\")]\n",
    "    acc_col = f\"{m}_accuracy\"\n",
    "    asr_col = f\"{m}_ASR\"\n",
    "\n",
    "    for t in tests:\n",
    "        adv_pred = preds[(m, t)]\n",
    "        accuracy = np.mean(adv_pred == clean_y)\n",
    "        if t == \"clean_train\":\n",
    "            asr = 0\n",
    "        else:\n",
    "            asr = np.sum((clean_pred == clean_y) & (adv_pred != clean_y))\n",
    "\n",
    "        df.at[t, acc_col] = accuracy\n",
    "        df.at[t, asr_col] = asr\n",
    "\n",
    "df"
   ],
   "id": "2e7dee92aa45c1e7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ok__\\AppData\\Local\\Temp\\ipykernel_19856\\1061342622.py:34: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.96' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  df.at[t, acc_col] = accuracy\n",
      "C:\\Users\\ok__\\AppData\\Local\\Temp\\ipykernel_19856\\1061342622.py:34: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.091' has dtype incompatible with float32, please explicitly cast to a compatible dtype first.\n",
      "  df.at[t, acc_col] = accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "               basic_accuracy  basic_ASR  robust_accuracy  robust_ASR\n",
       "clean_train             0.960        0.0            0.091         0.0\n",
       "basic_x_fgsm            0.326      639.0            0.085         7.0\n",
       "robust_x_fgsm           0.326      639.0            0.085         7.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>basic_accuracy</th>\n",
       "      <th>basic_ASR</th>\n",
       "      <th>robust_accuracy</th>\n",
       "      <th>robust_ASR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clean_train</th>\n",
       "      <td>0.960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basic_x_fgsm</th>\n",
       "      <td>0.326</td>\n",
       "      <td>639.0</td>\n",
       "      <td>0.085</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robust_x_fgsm</th>\n",
       "      <td>0.326</td>\n",
       "      <td>639.0</td>\n",
       "      <td>0.085</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
